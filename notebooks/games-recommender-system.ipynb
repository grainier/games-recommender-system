{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Comprehensive Video Game Recommendation System\n",
    "\n",
    "## Introduction\n",
    "In the rapidly growing video game industry, players often face the challenge of discovering new games that match their interests and preferences. With thousands of games released across various platforms and genres, finding the next game to play can be overwhelming. This project aims to address this challenge by developing a comprehensive video game recommendation system.\n",
    "\n",
    "Leveraging the `Video Game Sales with Ratings` dataset from Kaggle, our objective is to create a recommender system that suggests video games based on user preferences and game similarities. The dataset includes key information about video games such as titles, platforms, release years, genres, sales figures, and ratings, providing a rich source of data for building our models.\n",
    "\n",
    "We will explore multiple recommendation approaches to ensure a robust and versatile system:\n",
    "1. **Cosine Similarity-Based Recommender:** A content-based approach that measures the similarity between games based on their attributes.\n",
    "2. **Simple Recommender:** A non-personalized recommendation method that suggests popular games based on sales and ratings.\n",
    "3. **Content-Based Recommender:** Utilizes text-based features like game descriptions to find similar games.\n",
    "4. **Collaborative Filtering:** A personalized recommendation method that leverages user interaction data to suggest games.\n",
    "\n",
    "The project will be structured as follows:\n",
    "1. **Dataset Overview:** Introducing the dataset and its features.\n",
    "2. **Exploratory Data Analysis (EDA):** Performing a detailed analysis to understand data distributions, trends, and patterns.\n",
    "3. **Data Cleaning and Preprocessing:** Preparing the data by handling missing values, outliers, and encoding categorical variables.\n",
    "4. **Feature Selection:** Identifying the most relevant features for building effective recommendation models.\n",
    "5. **Model Training:** Implementing and training multiple recommendation models.\n",
    "6. **Model Evaluation:** Evaluating the performance of each model using appropriate metrics.\n",
    "7. **Comparison and Final Model Selection:** Comparing the models and selecting the best performing one.\n",
    "\n",
    "Through this comprehensive approach, we aim to deliver a recommendation system that enhances the gaming experience by providing personalized and relevant game suggestions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Overview\n",
    "The Dataset Overview section provides a comprehensive introduction to the Video_Games_Sales_as_at_22_Dec_2016.csv dataset. This dataset contains information about video game sales across various platforms up to December 22, 2016. It includes key features such as game titles, platforms, release years, genres, sales figures across different regions, and critic and user ratings. This section will load the dataset, display its structure, and summarize the main characteristics of the data, laying the foundation for further analysis and model building."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "file_path = '../data/Video_Games_Sales_as_at_22_Dec_2016.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display the summary of the dataset\n",
    "print(\"\\nDataset summary:\")\n",
    "display(df.info())\n",
    "\n",
    "# Display basic statistics for numerical columns\n",
    "print(\"\\nBasic statistics for numerical columns:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Display the list of columns and their descriptions\n",
    "print(\"\\nList of columns:\")\n",
    "columns = {\n",
    "    'Name': 'Name of the video game',\n",
    "    'Platform': 'Platform of the video game release (e.g., PS4, Xbox One, PC)',\n",
    "    'Year_of_Release': 'Year of release of the video game',\n",
    "    'Genre': 'Genre of the video game (e.g., Action, Sports, RPG)',\n",
    "    'Publisher': 'Publisher of the video game',\n",
    "    'NA_Sales': 'Sales in North America (in millions)',\n",
    "    'EU_Sales': 'Sales in Europe (in millions)',\n",
    "    'JP_Sales': 'Sales in Japan (in millions)',\n",
    "    'Other_Sales': 'Sales in other regions (in millions)',\n",
    "    'Global_Sales': 'Total worldwide sales (in millions)',\n",
    "    'Critic_Score': 'Aggregate score compiled by Metacritic staff (0-100)',\n",
    "    'Critic_Count': 'Number of critic reviews counted towards the Critic Score',\n",
    "    'User_Score': 'Score by Metacriticâ€™s subscribers (0-10)',\n",
    "    'User_Count': 'Number of user reviews counted towards the User Score',\n",
    "    'Developer': 'Developer of the video game',\n",
    "    'Rating': 'ESRB rating (e.g., E for Everyone, M for Mature)',\n",
    "}\n",
    "for col, desc in columns.items():\n",
    "    print(f\"{col}: {desc}\")\n",
    "\n",
    "# Display the number of missing values in each column\n",
    "print(\"\\nNumber of missing values in each column:\")\n",
    "display(df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summary of Dataset Overview**\n",
    "\n",
    "In this section, we have loaded the `Video_Games_Sales_as_at_22_Dec_2016.csv` dataset and provided an overview of its structure and contents. We displayed the first few rows to get an initial glimpse of the data, summarized the dataset's attributes, and highlighted the key features. Additionally, we listed the columns with their descriptions and identified missing values in the dataset. This comprehensive overview sets the stage for deeper exploratory data analysis and subsequent steps in building our recommendation system."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "The Exploratory Data Analysis (EDA) section aims to explore the `Video_Games_Sales_as_at_22_Dec_2016.csv` dataset in depth to understand its structure, distributions, and relationships between features. This step is crucial for uncovering insights and patterns that will guide the subsequent data preprocessing and model-building phases. We will use a variety of statistical summaries and visualizations to examine the distributions of sales figures, genre popularity, platform trends, and ratings. This comprehensive analysis will help identify any anomalies, trends, and key characteristics of the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting up visual styles\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Displaying the first few rows of the dataset again for reference\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# 1. Distribution of Global Sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Global_Sales'], kde=True, bins=30)\n",
    "plt.title('Distribution of Global Sales')\n",
    "plt.xlabel('Global Sales (in millions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Sales by Genre\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Genre', y='Global_Sales', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Global Sales by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Global Sales (in millions)')\n",
    "plt.show()\n",
    "\n",
    "# 3. Sales by Platform\n",
    "plt.figure(figsize=(14, 8))\n",
    "platform_sales = df.groupby('Platform')['Global_Sales'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=platform_sales.index, y=platform_sales.values, palette='viridis')\n",
    "plt.title('Total Global Sales by Platform')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Total Global Sales (in millions)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# 4. Sales by Year of Release\n",
    "plt.figure(figsize=(14, 8))\n",
    "year_sales = df.groupby('Year_of_Release')['Global_Sales'].sum().sort_index()\n",
    "sns.lineplot(x=year_sales.index, y=year_sales.values)\n",
    "plt.title('Total Global Sales by Year of Release')\n",
    "plt.xlabel('Year of Release')\n",
    "plt.ylabel('Total Global Sales (in millions)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# 5. Distribution of Critic Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Critic_Score'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribution of Critic Scores')\n",
    "plt.xlabel('Critic Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 6. Distribution of User Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['User_Score'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribution of User Scores')\n",
    "plt.xlabel('User Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 7. Correlation Heatmap (excluding non-numeric columns)\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])  # Selecting only numeric columns\n",
    "correlation_matrix = numeric_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.show()\n",
    "\n",
    "# 8. Distribution of Genres\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(y='Genre', data=df, order=df['Genre'].value_counts().index, palette='viridis')\n",
    "plt.title('Distribution of Genres')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Genre')\n",
    "plt.show()\n",
    "\n",
    "# 9. Distribution of Platforms\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(y='Platform', data=df, order=df['Platform'].value_counts().index, palette='viridis')\n",
    "plt.title('Distribution of Platforms')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Platform')\n",
    "plt.show()\n",
    "\n",
    "# 10. Distribution of Ratings\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(y='Rating', data=df, order=df['Rating'].value_counts().index, palette='viridis')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summary of Exploratory Data Analysis (EDA)**\n",
    "In this EDA section, we explored the Video_Games_Sales_as_at_22_Dec_2016.csv dataset through various visualizations and statistical summaries. We analyzed the distribution of global sales, examined sales trends across different genres, platforms, and years of release, and visualized the distributions of critic and user scores. Additionally, we created a correlation heatmap to identify relationships between numerical features and explored the distributions of genres, platforms, and ratings.\n",
    "\n",
    "We observed that there is a scarcity of data for certain platforms such as DC and certain ratings such as 'K-A', 'AO', 'EC', and 'RP'. These insights provide a deeper understanding of the dataset and will inform our data preprocessing and feature selection strategies in the subsequent steps."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "The Data Cleaning and Preprocessing section focuses on preparing the dataset for modeling by handling missing values, creating new features, and transforming the data. This involves removing records with missing critical data, imputing missing values for scores, converting categorical features to dummy variables, and standardizing numerical data. These steps ensure that the dataset is clean, consistent, and suitable for building effective recommendation models.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the initial summary of the dataset\n",
    "print(\"Initial dataset summary:\")\n",
    "display(df.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Remove records with missing data in 'Name', 'Genre', and 'Rating'\n",
    "df = df.dropna(subset=['Name', 'Genre', 'Rating'])\n",
    "print(\"\\nDataset summary after removing records with missing 'Name', 'Genre', and 'Rating':\")\n",
    "display(df.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. Create additional features for User_Score and Critic_Score and impute missing values\n",
    "\n",
    "# Replace 'tbd' value to NaN\n",
    "df['User_Score'] = np.where(df['User_Score'] == 'tbd', np.nan, df['User_Score']).astype(float)\n",
    "\n",
    "# Group the records by Genre, then aggregate them calculating the average of both Critic Score and User Score\n",
    "df_grp_by_genre = df[['Genre', 'Critic_Score', 'User_Score']].groupby('Genre', as_index=False)\n",
    "df_score_mean = df_grp_by_genre.agg(Ave_Critic_Score = ('Critic_Score', 'mean'), Ave_User_Score = ('User_Score', 'mean'))\n",
    "\n",
    "# Merge the average scores with the main dataframe\n",
    "df = df.merge(df_score_mean, on='Genre')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. Impute missing values by calculating the mean within each genre\n",
    "df['Critic_Score_Imputed'] = np.where(df['Critic_Score'].isna(), df['Ave_Critic_Score'], df['Critic_Score'])\n",
    "df['User_Score_Imputed'] = np.where(df['User_Score'].isna(), df['Ave_User_Score'], df['User_Score'])\n",
    "\n",
    "print(\"\\nSummary statistics for User_Score and User_Score_Imputed:\")\n",
    "display(df[['User_Score', 'User_Score_Imputed']].describe())\n",
    "\n",
    "print(\"\\nSummary statistics for Critic_Score and Critic_Score_Imputed:\")\n",
    "display(df[['Critic_Score', 'Critic_Score_Imputed']].describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. Drop fields related to critic and user scores except for the new features with imputed values\n",
    "final_df = df.drop(columns=['User_Score', 'Critic_Score', 'Ave_Critic_Score', 'Ave_User_Score'], axis=1)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df = final_df.rename(columns={'Critic_Score_Imputed':'Critic_Score', 'User_Score_Imputed':'User_Score'})\n",
    "\n",
    "# 5. Filter out only required columns\n",
    "final_df = final_df[['Name', 'Platform', 'Genre', 'Rating', 'Critic_Score', 'User_Score']]\n",
    "final_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. Analyze the data distribution for `Critic_Score` and `User_Score`\n",
    "\n",
    "# Distribution of Critic Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(final_df['Critic_Score'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribution of Critic Scores')\n",
    "plt.xlabel('Critic Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of User Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(final_df['User_Score'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribution of User Scores')\n",
    "plt.xlabel('User Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of User Scores\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.regplot(x=final_df['User_Score'], y=final_df['Critic_Score'], line_kws={\"color\": \"black\"}, scatter_kws={'s': 4})\n",
    "ax.set(xlabel =\"User Score\", ylabel = \"Critic Score\", title=\"User Scores vs. Critic Scores\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7. Converting Categorical Features to Dummy Indicators\n",
    "categorical_features = [name for name in final_df.columns if final_df[name].dtype=='O']\n",
    "categorical_features = categorical_features[1:] # except for the name\n",
    "\n",
    "df_preprocessed = pd.get_dummies(data=final_df, columns=categorical_features)\n",
    "df_preprocessed.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9950 entries, 0 to 9949\n",
      "Data columns (total 39 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Critic_Score        9950 non-null   float64\n",
      " 1   User_Score          9950 non-null   float64\n",
      " 2   Platform_3DS        9950 non-null   float64\n",
      " 3   Platform_DC         9950 non-null   float64\n",
      " 4   Platform_DS         9950 non-null   float64\n",
      " 5   Platform_GBA        9950 non-null   float64\n",
      " 6   Platform_GC         9950 non-null   float64\n",
      " 7   Platform_PC         9950 non-null   float64\n",
      " 8   Platform_PS         9950 non-null   float64\n",
      " 9   Platform_PS2        9950 non-null   float64\n",
      " 10  Platform_PS3        9950 non-null   float64\n",
      " 11  Platform_PS4        9950 non-null   float64\n",
      " 12  Platform_PSP        9950 non-null   float64\n",
      " 13  Platform_PSV        9950 non-null   float64\n",
      " 14  Platform_Wii        9950 non-null   float64\n",
      " 15  Platform_WiiU       9950 non-null   float64\n",
      " 16  Platform_X360       9950 non-null   float64\n",
      " 17  Platform_XB         9950 non-null   float64\n",
      " 18  Platform_XOne       9950 non-null   float64\n",
      " 19  Genre_Action        9950 non-null   float64\n",
      " 20  Genre_Adventure     9950 non-null   float64\n",
      " 21  Genre_Fighting      9950 non-null   float64\n",
      " 22  Genre_Misc          9950 non-null   float64\n",
      " 23  Genre_Platform      9950 non-null   float64\n",
      " 24  Genre_Puzzle        9950 non-null   float64\n",
      " 25  Genre_Racing        9950 non-null   float64\n",
      " 26  Genre_Role-Playing  9950 non-null   float64\n",
      " 27  Genre_Shooter       9950 non-null   float64\n",
      " 28  Genre_Simulation    9950 non-null   float64\n",
      " 29  Genre_Sports        9950 non-null   float64\n",
      " 30  Genre_Strategy      9950 non-null   float64\n",
      " 31  Rating_AO           9950 non-null   float64\n",
      " 32  Rating_E            9950 non-null   float64\n",
      " 33  Rating_E10+         9950 non-null   float64\n",
      " 34  Rating_EC           9950 non-null   float64\n",
      " 35  Rating_K-A          9950 non-null   float64\n",
      " 36  Rating_M            9950 non-null   float64\n",
      " 37  Rating_RP           9950 non-null   float64\n",
      " 38  Rating_T            9950 non-null   float64\n",
      "dtypes: float64(39)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "# 8. Standardizing the Numerical Features\n",
    "features = df_preprocessed.drop(columns=['Name'], axis=1)\n",
    "scale = StandardScaler()\n",
    "scaled_features = scale.fit_transform(features)\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "scaled_features.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T10:02:02.297848Z",
     "start_time": "2024-06-20T10:02:02.269518Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summary of Data Cleaning and Preprocessing**\n",
    "In the Data Cleaning and Preprocessing section, we performed several crucial steps to prepare the dataset for modeling. We removed records with missing data in the Name, Genre, and Rating features. We created additional features for `User_Score` and `Critic_Score`, imputing missing values with the mean value within each genre. We dropped fields related to critic and user scores except for the newly created imputed features and retained only the required columns.\n",
    "\n",
    "We analyzed the data distribution for `Critic_Score` and `User_Score`, observing their distribution patterns and correlation. We transformed all categorical features into binary dummy variables and standardized numerical data to ensure that all features are on a similar scale.\n",
    "\n",
    "The resulting preprocessed dataset has 9950 entries and 39 features, ready for building effective recommendation models. The analysis highlighted the scarcity of data for certain platforms and ratings, which will be considered during feature selection and model evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
